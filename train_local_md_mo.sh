python -m swarm_rl.train \
--env=quadrotor_multi --train_for_env_steps=1000000000 --algo=APPO --use_rnn=False \
--num_workers=1 --num_envs_per_worker=4 --learning_rate=0.003 --ppo_clip_value=5.0 --recurrence=1 \
--nonlinearity=tanh --actor_critic_share_weights=False --policy_initialization=xavier_uniform \
--adaptive_stddev=False --with_vtrace=False --max_policy_lag=100000000 --rnn_size=24 \
--gae_lambda=1.00 --max_grad_norm=5.0 --exploration_loss_coeff=0.0 --rollout=128 --batch_size=1024 \
--with_pbt=False --normalize_input=False --normalize_returns=False --reward_clip=10 \
--quads_use_numba=True --save_milestones_sec=3600 --anneal_collision_steps=300000000 \
--replay_buffer_sample_prob=0.0 \
--quads_mode=o_static_same_goal --quads_episode_duration=15.0 \
--quads_obs_repr=xyz_vxyz_R_omega --quads_sim2real=True --quads_encoder_type=attention --quads_num_agents=8 \
--quads_neighbor_hidden_size=8 --quads_neighbor_obs_type=pos --quads_collision_hitbox_radius=2.0 \
--quads_collision_falloff_radius=4.0 --quads_collision_reward=5.0 --quads_collision_smooth_max_penalty=4.0 \
--quads_neighbor_encoder_type=mlp --quads_neighbor_visible_num=2 \
--quads_use_obstacles=True --quads_obst_spawn_area 8 8 --quads_obst_density=0.2 --quads_obst_size=0.3 --quads_obstacle_obs_type=ToFs \
--quads_obst_grid_size=0.5 --quads_obst_spawn_center=False --quads_obst_grid_size_range 0.5 0.8 --quads_use_downwash=True \
--quads_obstacle_tof_resolution=8 --quads_obst_hidden_size=8 --quads_obst_collision_reward=5.0 \
--with_wandb=True --wandb_project=Quad-Swarm-RL --wandb_user=darren-personal --wandb_group=md_mo_baseline_local \
--experiment=test_multi_drone_attention \